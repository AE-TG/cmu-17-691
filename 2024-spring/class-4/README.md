# Class Notes
Type your notes into this file and then submit them as a pull request within 1 week of the class.

Deciding If ML Is Right for Our Project:
•	Assessing ML's Fit:
o	Consider if ML is the right choice for the issue at hand.
•	Steps to Check Feasibility:
1.	Understanding the Problem: Clearly identify the problem and who it helps.
2.	Review Existing Work: Explore research to see what’s been achieved and if you need to beat the top results.
3.	Gather Initial Data: Collect a small dataset (100-1,000 labels) for early testing.
4.	Build a Simple MVP: Create a basic MVP to see how ML might improve your solution.
5.	Reevaluate ML's Need: Decide if ML is truly necessary after these steps.
Picking Evaluation Metrics:
•	Model Metrics:
o	Focus on what matters: accuracy, false positives vs. false negatives, and how it deals with unusual data. Choose a cost function that fits your project.
•	Value in Your Industry:
o	Think about how metrics contribute to value in your field. See how basic models compare to help choose your metrics.
Integrating ML Insights and AutoML:
•	Best ML Practices:
o	Stress on good engineering, starting simple, and learning as you evolve your model.
•	Using Amazon Rekognition & AWS AutoML:
o	These showcase how to seamlessly include ML in projects, providing a roadmap from data prep to evaluation.
•	Vertex AI and AutoML Insights:
o	Points out how simplifying ML tasks is possible, allowing for the creation of accurate models with less coding. This supports beginning with manageable datasets and simplifying the ML process with AutoML tools.

